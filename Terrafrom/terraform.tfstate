{
  "version": 4,
  "terraform_version": "0.14.8",
  "serial": 43,
  "lineage": "2ca04b4e-1f4d-ee01-8b7c-e1feb592686f",
  "outputs": {},
  "resources": [
    {
      "mode": "data",
      "type": "template_file",
      "name": "grafana_values",
      "provider": "provider[\"registry.terraform.io/hashicorp/template\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "d316dd6fce0a7b13cd7ce7876b0f03ee7856365b44af3645dd1cf0e2099687e9",
            "rendered": "rbac:\n  create: true\n  pspEnabled: true\n  pspUseAppArmor: true\n  namespaced: true\n  extraRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\n  extraClusterRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\nserviceAccount:\n  create: true\n  name: grafana\n  nameTest:\n#  annotations:\n\nreplicas: 1\n\n## See `kubectl explain poddisruptionbudget.spec` for more\n## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\npodDisruptionBudget: {}\n#  minAvailable: 1\n#  maxUnavailable: 1\n\n## See `kubectl explain deployment.spec.strategy` for more\n## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy\ndeploymentStrategy:\n  type: RollingUpdate\n\nreadinessProbe:\n  httpGet:\n    path: /api/health\n    port: 3000\n\nlivenessProbe:\n  httpGet:\n    path: /api/health\n    port: 3000\n  initialDelaySeconds: 60\n  timeoutSeconds: 30\n  failureThreshold: 10\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName: \"default-scheduler\"\n\nimage:\n  repository: grafana/grafana\n  tag: 7.1.1\n  sha: \"\"\n  pullPolicy: IfNotPresent\n\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistrKeySecretName\n\ntestFramework:\n  enabled: true\n  image: \"bats/bats\"\n  tag: \"v1.1.0\"\n  imagePullPolicy: IfNotPresent\n  securityContext: {}\n\nsecurityContext:\n  runAsUser: 472\n  runAsGroup: 472\n  fsGroup: 472\n\n\nextraConfigmapMounts: []\n  # - name: certs-configmap\n  #   mountPath: /etc/grafana/ssl/\n  #   subPath: certificates.crt # (optional)\n  #   configMap: certs-configmap\n#   readOnly: true\n\n\nextraEmptyDirMounts: []\n  # - name: provisioning-notifiers\n#   mountPath: /etc/grafana/provisioning/notifiers\n\n\n## Assign a PriorityClassName to pods if set\n# priorityClassName:\n\ndownloadDashboardsImage:\n  repository: curlimages/curl\n  tag: 7.70.0\n  sha: \"\"\n  pullPolicy: IfNotPresent\n\ndownloadDashboards:\n  env: {}\n  resources: {}\n\n## Pod Annotations\n# podAnnotations: {}\n\n## Pod Labels\npodLabels:\n  app: grafana\n\npodPortName: grafana\n\n## Deployment annotations\n# annotations: {}\n\n## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).\n## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.\n## ref: http://kubernetes.io/docs/user-guide/services/\n##\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 3000\n  # targetPort: 4181 To be used with a proxy extraContainer\n  annotations: {}\n  labels:\n    app: grafana\n  portName: service\n\nextraExposePorts: []\n  # - name: keycloak\n  #   port: 8080\n  #   targetPort: 8080\n#   type: ClusterIP\n\n# overrides pod.spec.hostAliases in the grafana deployment's pods\nhostAliases: []\n  # - ip: \"1.2.3.4\"\n  #   hostnames:\n#     - \"my.host.com\"\n\ningress:\n  enabled: false\n  # Values can be templated\n  annotations: {}\n    # kubernetes.io/ingress.class: nginx\n  # kubernetes.io/tls-acme: \"true\"\n  labels: {}\n  path: /\n  hosts:\n    - chart-example.local\n  ## Extra paths to prepend to every host configuration. This is useful when working with annotation based services.\n  extraPaths: []\n  # - path: /*\n  #   backend:\n  #     serviceName: ssl-redirect\n  #     servicePort: use-annotation\n  tls: []\n  #  - secretName: chart-example-tls\n  #    hosts:\n  #      - chart-example.local\n\nresources:\n  limits:\n    cpu: 100m\n    memory: 128Mi\n  requests:\n    cpu: 100m\n    memory: 128Mi\n\n## Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n#\nnodeSelector: {}\n\n## Tolerations for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n\n## Affinity for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n\nextraInitContainers: []\n\n## Enable an Specify container in extraContainers. This is meant to allow adding an authentication proxy to a grafana pod\nextraContainers: |\n# - name: proxy\n#   image: quay.io/gambol99/keycloak-proxy:latest\n#   args:\n#   - -provider=github\n#   - -client-id=\n#   - -client-secret=\n#   - -github-org=\u003cORG_NAME\u003e\n#   - -email-domain=*\n#   - -cookie-secret=\n#   - -http-address=http://0.0.0.0:4181\n#   - -upstream-url=http://127.0.0.1:3000\n#   ports:\n#     - name: proxy-web\n#       containerPort: 4181\n\n## Volumes that can be used in init containers that will not be mounted to deployment pods\nextraContainerVolumes: []\n#  - name: volume-from-secret\n#    secret:\n#      secretName: secret-to-mount\n#  - name: empty-dir-volume\n#    emptyDir: {}\n\n## Enable persistence using Persistent Volume Claims\n## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n##\npersistence:\n  type: pvc\n  enabled: false\n  # storageClassName: default\n  accessModes:\n    - ReadWriteOnce\n  size: 10Gi\n  # annotations: {}\n  finalizers:\n    - kubernetes.io/pvc-protection\n  # subPath: \"\"\n  # existingClaim:\n\ninitChownData:\n  ## If false, data ownership will not be reset at startup\n  ## This allows the prometheus-server to be run with an arbitrary user\n  ##\n  enabled: true\n\n  ## initChownData container image\n  ##\n  image:\n    repository: busybox\n    tag: \"1.31.1\"\n    sha: \"\"\n    pullPolicy: IfNotPresent\n\n  ## initChownData resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 128Mi\n\n\n# Administrator credentials when not using an existing secret (see below)\nadminUser: admin\nadminPassword: 5028\n\n## Define command to be executed at startup by grafana container\n## Needed if using `vault-env` to manage secrets (ref: https://banzaicloud.com/blog/inject-secrets-into-pods-vault/)\n## Default is \"run.sh\" as defined in grafana's Dockerfile\n# command:\n# - \"sh\"\n# - \"/run.sh\"\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName:\n\n## Extra environment variables that will be pass onto deployment pods\nenv: {}\n\n## \"valueFrom\" environment variable references that will be added to deployment pods\n## ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#envvarsource-v1-core\n## Renders in container spec as:\n##   env:\n##     ...\n##     - name: \u003ckey\u003e\n##       valueFrom:\n##         \u003cvalue rendered as YAML\u003e\nenvValueFrom: {}\n\n## The name of a secret in the same kubernetes namespace which contain values to be added to the environment\n## This can be useful for auth tokens, etc. Value is templated.\nenvFromSecret: \"\"\n\n## Sensible environment variables that will be rendered as new secret object\n## This can be useful for auth tokens, etc\nenvRenderSecret: {}\n\n## Additional grafana server secret mounts\n# Defines additional mounts with secrets. Secrets must be manually created in the namespace.\nextraSecretMounts: []\n  # - name: secret-files\n  #   mountPath: /etc/secrets\n  #   secretName: grafana-secret-files\n  #   readOnly: true\n#   subPath: \"\"\n\n## Additional grafana server volume mounts\n# Defines additional volume mounts.\nextraVolumeMounts: []\n  # - name: extra-volume\n  #   mountPath: /mnt/volume\n  #   readOnly: true\n#   existingClaim: volume-claim\n\n## Pass the plugins you want installed as a list.\n##\nplugins: []\n  # - digrich-bubblechart-panel\n# - grafana-clock-panel\n\n## Configure grafana datasources\n## ref: http://docs.grafana.org/administration/provisioning/#datasources\n##\ndatasources:\n  datasources.yaml:\n    apiVersion: 1\n    datasources:\n    - name: Prometheus\n      type: prometheus\n      url: http://prometheus-server.grafana.svc.cluster.local\n      access: proxy\n      isDefault: true\n\n## Configure notifiers\n## ref: http://docs.grafana.org/administration/provisioning/#alert-notification-channels\n##\nnotifiers: {}\n#  notifiers.yaml:\n#    notifiers:\n#    - name: email-notifier\n#      type: email\n#      uid: email1\n#      # either:\n#      org_id: 1\n#      # or\n#      org_name: Main Org.\n#      is_default: true\n#      settings:\n#        addresses: an_email_address@example.com\n#    delete_notifiers:\n\n## Configure grafana dashboard providers\n## ref: http://docs.grafana.org/administration/provisioning/#dashboards\n##\n## `path` must be /var/lib/grafana/dashboards/\u003cprovider_name\u003e\n##\ndashboardProviders:\n  dashboardproviders.yaml:\n    apiVersion: 1\n    providers:\n    - name: 'default'\n      orgId: 1\n      folder: ''\n      type: file\n      disableDeletion: false\n      editable: true\n      options:\n        path: /var/lib/grafana/dashboards/default\n\n## Configure grafana dashboard to import\n## NOTE: To use dashboards you must also enable/configure dashboardProviders\n## ref: https://grafana.com/dashboards\n##\n## dashboards per provider, use provider name as key.\n##\ndashboards:\n  # default:\n  #   some-dashboard:\n  #     json: |\n  #       $RAW_JSON\n  #   custom-dashboard:\n  #     file: dashboards/custom-dashboard.json\n  #   prometheus-stats:\n  #     gnetId: 2\n  #     revision: 2\n  #     datasource: Prometheus\n  #   local-dashboard:\n  #     url: https://example.com/repository/test.json\n  #   local-dashboard-base64:\n  #     url: https://example.com/repository/test-b64.json\n  #   b64content: true\n  default:\n    prometheus-stats:\n      gnetId: 10000\n      revision: 1\n      datasource: Prometheus\n\n\n\n## Reference to external ConfigMap per provider. Use provider name as key and ConfiMap name as value.\n## A provider dashboards must be defined either by external ConfigMaps or in values.yaml, not in both.\n## ConfigMap data example:\n##\n## data:\n##   example-dashboard.json: |\n##     RAW_JSON\n##\ndashboardsConfigMaps: {}\n#  default: \"\"\n\n## Grafana's primary configuration\n## NOTE: values in map will be converted to ini format\n## ref: http://docs.grafana.org/installation/configuration/\n##\ngrafana.ini:\n  paths:\n    data: /var/lib/grafana/data\n    logs: /var/log/grafana\n    plugins: /var/lib/grafana/plugins\n    provisioning: /etc/grafana/provisioning\n  analytics:\n    check_for_updates: true\n  log:\n    mode: console\n  grafana_net:\n    url: https://grafana.net\n      ## grafana Authentication can be enabled with the following values on grafana.ini\n      # server:\n    # The full public facing url you use in browser, used for redirects and emails\n  #    root_url:\n  # https://grafana.com/docs/grafana/latest/auth/github/#enable-github-in-grafana\n  # auth.github:\n  #    enabled: false\n  #    allow_sign_up: false\n  #    scopes: user:email,read:org\n  #    auth_url: https://github.com/login/oauth/authorize\n  #    token_url: https://github.com/login/oauth/access_token\n  #    api_url: https://github.com/user\n  #    team_ids:\n  #    allowed_organizations:\n  #    client_id:\n  #    client_secret:\n  ## LDAP Authentication can be enabled with the following values on grafana.ini\n  ## NOTE: Grafana will fail to start if the value for ldap.toml is invalid\n  # auth.ldap:\n  #   enabled: true\n  #   allow_sign_up: true\n  #   config_file: /etc/grafana/ldap.toml\n\n## Grafana's LDAP configuration\n## Templated by the template in _helpers.tpl\n## NOTE: To enable the grafana.ini must be configured with auth.ldap.enabled\n## ref: http://docs.grafana.org/installation/configuration/#auth-ldap\n## ref: http://docs.grafana.org/installation/ldap/#configuration\nldap:\n  enabled: false\n  # `existingSecret` is a reference to an existing secret containing the ldap configuration\n  # for Grafana in a key `ldap-toml`.\n  existingSecret: \"\"\n  # `config` is the content of `ldap.toml` that will be stored in the created secret\n  config: \"\"\n  # config: |-\n  #   verbose_logging = true\n\n  #   [[servers]]\n  #   host = \"my-ldap-server\"\n  #   port = 636\n  #   use_ssl = true\n  #   start_tls = false\n  #   ssl_skip_verify = false\n  #   bind_dn = \"uid=%s,ou=users,dc=myorg,dc=com\"\n\n## Grafana's SMTP configuration\n## NOTE: To enable, grafana.ini must be configured with smtp.enabled\n## ref: http://docs.grafana.org/installation/configuration/#smtp\nsmtp:\n  # `existingSecret` is a reference to an existing secret containing the smtp configuration\n  # for Grafana.\n  existingSecret: \"\"\n  userKey: \"user\"\n  passwordKey: \"password\"\n\n## Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders\n## Requires at least Grafana 5 to work and can't be used together with parameters dashboardProviders, datasources and dashboards\nsidecar:\n  image:\n    repository: kiwigrid/k8s-sidecar\n    tag: 0.1.151\n    sha: \"\"\n  imagePullPolicy: IfNotPresent\n  resources: {}\n  #   limits:\n  #     cpu: 100m\n  #     memory: 100Mi\n  #   requests:\n  #     cpu: 50m\n  #     memory: 50Mi\n  # skipTlsVerify Set to true to skip tls verification for kube api calls\n  # skipTlsVerify: true\n  enableUniqueFilenames: false\n  dashboards:\n    enabled: false\n    SCProvider: true\n    # label that the configmaps with dashboards are marked with\n    label: grafana_dashboard\n    # folder in the pod that should hold the collected dashboards (unless `defaultFolderName` is set)\n    folder: /tmp/dashboards\n    # The default folder name, it will create a subfolder under the `folder` and put dashboards in there instead\n    defaultFolderName: null\n    # If specified, the sidecar will search for dashboard config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n    # provider configuration that lets grafana manage the dashboards\n    provider:\n      # name of the provider, should be unique\n      name: sidecarProvider\n      # orgid as configured in grafana\n      orgid: 1\n      # folder in which the dashboards should be imported in grafana\n      folder: ''\n      # type of the provider\n      type: file\n      # disableDelete to activate a import-only behaviour\n      disableDelete: false\n      # allow updating provisioned dashboards from the UI\n      allowUiUpdates: false\n  datasources:\n    enabled: false\n    # label that the configmaps with datasources are marked with\n    label: grafana_datasource\n    # If specified, the sidecar will search for datasource config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n  notifiers:\n    enabled: false\n    # label that the configmaps with notifiers are marked with\n    label: grafana_notifier\n    # If specified, the sidecar will search for notifier config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n\n## Override the deployment namespace\n##\nnamespaceOverride: \"\"\n",
            "template": "rbac:\n  create: true\n  pspEnabled: true\n  pspUseAppArmor: true\n  namespaced: true\n  extraRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\n  extraClusterRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\nserviceAccount:\n  create: true\n  name: ${GRAFANA_SERVICE_ACCOUNT}\n  nameTest:\n#  annotations:\n\nreplicas: 1\n\n## See `kubectl explain poddisruptionbudget.spec` for more\n## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\npodDisruptionBudget: {}\n#  minAvailable: 1\n#  maxUnavailable: 1\n\n## See `kubectl explain deployment.spec.strategy` for more\n## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy\ndeploymentStrategy:\n  type: RollingUpdate\n\nreadinessProbe:\n  httpGet:\n    path: /api/health\n    port: 3000\n\nlivenessProbe:\n  httpGet:\n    path: /api/health\n    port: 3000\n  initialDelaySeconds: 60\n  timeoutSeconds: 30\n  failureThreshold: 10\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName: \"default-scheduler\"\n\nimage:\n  repository: grafana/grafana\n  tag: 7.1.1\n  sha: \"\"\n  pullPolicy: IfNotPresent\n\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistrKeySecretName\n\ntestFramework:\n  enabled: true\n  image: \"bats/bats\"\n  tag: \"v1.1.0\"\n  imagePullPolicy: IfNotPresent\n  securityContext: {}\n\nsecurityContext:\n  runAsUser: 472\n  runAsGroup: 472\n  fsGroup: 472\n\n\nextraConfigmapMounts: []\n  # - name: certs-configmap\n  #   mountPath: /etc/grafana/ssl/\n  #   subPath: certificates.crt # (optional)\n  #   configMap: certs-configmap\n#   readOnly: true\n\n\nextraEmptyDirMounts: []\n  # - name: provisioning-notifiers\n#   mountPath: /etc/grafana/provisioning/notifiers\n\n\n## Assign a PriorityClassName to pods if set\n# priorityClassName:\n\ndownloadDashboardsImage:\n  repository: curlimages/curl\n  tag: 7.70.0\n  sha: \"\"\n  pullPolicy: IfNotPresent\n\ndownloadDashboards:\n  env: {}\n  resources: {}\n\n## Pod Annotations\n# podAnnotations: {}\n\n## Pod Labels\npodLabels:\n  app: grafana\n\npodPortName: grafana\n\n## Deployment annotations\n# annotations: {}\n\n## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).\n## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.\n## ref: http://kubernetes.io/docs/user-guide/services/\n##\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 3000\n  # targetPort: 4181 To be used with a proxy extraContainer\n  annotations: {}\n  labels:\n    app: grafana\n  portName: service\n\nextraExposePorts: []\n  # - name: keycloak\n  #   port: 8080\n  #   targetPort: 8080\n#   type: ClusterIP\n\n# overrides pod.spec.hostAliases in the grafana deployment's pods\nhostAliases: []\n  # - ip: \"1.2.3.4\"\n  #   hostnames:\n#     - \"my.host.com\"\n\ningress:\n  enabled: false\n  # Values can be templated\n  annotations: {}\n    # kubernetes.io/ingress.class: nginx\n  # kubernetes.io/tls-acme: \"true\"\n  labels: {}\n  path: /\n  hosts:\n    - chart-example.local\n  ## Extra paths to prepend to every host configuration. This is useful when working with annotation based services.\n  extraPaths: []\n  # - path: /*\n  #   backend:\n  #     serviceName: ssl-redirect\n  #     servicePort: use-annotation\n  tls: []\n  #  - secretName: chart-example-tls\n  #    hosts:\n  #      - chart-example.local\n\nresources:\n  limits:\n    cpu: 100m\n    memory: 128Mi\n  requests:\n    cpu: 100m\n    memory: 128Mi\n\n## Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n#\nnodeSelector: {}\n\n## Tolerations for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n\n## Affinity for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n\nextraInitContainers: []\n\n## Enable an Specify container in extraContainers. This is meant to allow adding an authentication proxy to a grafana pod\nextraContainers: |\n# - name: proxy\n#   image: quay.io/gambol99/keycloak-proxy:latest\n#   args:\n#   - -provider=github\n#   - -client-id=\n#   - -client-secret=\n#   - -github-org=\u003cORG_NAME\u003e\n#   - -email-domain=*\n#   - -cookie-secret=\n#   - -http-address=http://0.0.0.0:4181\n#   - -upstream-url=http://127.0.0.1:3000\n#   ports:\n#     - name: proxy-web\n#       containerPort: 4181\n\n## Volumes that can be used in init containers that will not be mounted to deployment pods\nextraContainerVolumes: []\n#  - name: volume-from-secret\n#    secret:\n#      secretName: secret-to-mount\n#  - name: empty-dir-volume\n#    emptyDir: {}\n\n## Enable persistence using Persistent Volume Claims\n## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n##\npersistence:\n  type: pvc\n  enabled: false\n  # storageClassName: default\n  accessModes:\n    - ReadWriteOnce\n  size: 10Gi\n  # annotations: {}\n  finalizers:\n    - kubernetes.io/pvc-protection\n  # subPath: \"\"\n  # existingClaim:\n\ninitChownData:\n  ## If false, data ownership will not be reset at startup\n  ## This allows the prometheus-server to be run with an arbitrary user\n  ##\n  enabled: true\n\n  ## initChownData container image\n  ##\n  image:\n    repository: busybox\n    tag: \"1.31.1\"\n    sha: \"\"\n    pullPolicy: IfNotPresent\n\n  ## initChownData resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 128Mi\n\n\n# Administrator credentials when not using an existing secret (see below)\nadminUser: ${GRAFANA_ADMIN_USER}\nadminPassword: ${GRAFANA_ADMIN_PASSWORD}\n\n## Define command to be executed at startup by grafana container\n## Needed if using `vault-env` to manage secrets (ref: https://banzaicloud.com/blog/inject-secrets-into-pods-vault/)\n## Default is \"run.sh\" as defined in grafana's Dockerfile\n# command:\n# - \"sh\"\n# - \"/run.sh\"\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName:\n\n## Extra environment variables that will be pass onto deployment pods\nenv: {}\n\n## \"valueFrom\" environment variable references that will be added to deployment pods\n## ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#envvarsource-v1-core\n## Renders in container spec as:\n##   env:\n##     ...\n##     - name: \u003ckey\u003e\n##       valueFrom:\n##         \u003cvalue rendered as YAML\u003e\nenvValueFrom: {}\n\n## The name of a secret in the same kubernetes namespace which contain values to be added to the environment\n## This can be useful for auth tokens, etc. Value is templated.\nenvFromSecret: \"\"\n\n## Sensible environment variables that will be rendered as new secret object\n## This can be useful for auth tokens, etc\nenvRenderSecret: {}\n\n## Additional grafana server secret mounts\n# Defines additional mounts with secrets. Secrets must be manually created in the namespace.\nextraSecretMounts: []\n  # - name: secret-files\n  #   mountPath: /etc/secrets\n  #   secretName: grafana-secret-files\n  #   readOnly: true\n#   subPath: \"\"\n\n## Additional grafana server volume mounts\n# Defines additional volume mounts.\nextraVolumeMounts: []\n  # - name: extra-volume\n  #   mountPath: /mnt/volume\n  #   readOnly: true\n#   existingClaim: volume-claim\n\n## Pass the plugins you want installed as a list.\n##\nplugins: []\n  # - digrich-bubblechart-panel\n# - grafana-clock-panel\n\n## Configure grafana datasources\n## ref: http://docs.grafana.org/administration/provisioning/#datasources\n##\ndatasources:\n  datasources.yaml:\n    apiVersion: 1\n    datasources:\n    - name: Prometheus\n      type: prometheus\n      url: http://${PROMETHEUS_SVC}.${NAMESPACE}.svc.cluster.local\n      access: proxy\n      isDefault: true\n\n## Configure notifiers\n## ref: http://docs.grafana.org/administration/provisioning/#alert-notification-channels\n##\nnotifiers: {}\n#  notifiers.yaml:\n#    notifiers:\n#    - name: email-notifier\n#      type: email\n#      uid: email1\n#      # either:\n#      org_id: 1\n#      # or\n#      org_name: Main Org.\n#      is_default: true\n#      settings:\n#        addresses: an_email_address@example.com\n#    delete_notifiers:\n\n## Configure grafana dashboard providers\n## ref: http://docs.grafana.org/administration/provisioning/#dashboards\n##\n## `path` must be /var/lib/grafana/dashboards/\u003cprovider_name\u003e\n##\ndashboardProviders:\n  dashboardproviders.yaml:\n    apiVersion: 1\n    providers:\n    - name: 'default'\n      orgId: 1\n      folder: ''\n      type: file\n      disableDeletion: false\n      editable: true\n      options:\n        path: /var/lib/grafana/dashboards/default\n\n## Configure grafana dashboard to import\n## NOTE: To use dashboards you must also enable/configure dashboardProviders\n## ref: https://grafana.com/dashboards\n##\n## dashboards per provider, use provider name as key.\n##\ndashboards:\n  # default:\n  #   some-dashboard:\n  #     json: |\n  #       $RAW_JSON\n  #   custom-dashboard:\n  #     file: dashboards/custom-dashboard.json\n  #   prometheus-stats:\n  #     gnetId: 2\n  #     revision: 2\n  #     datasource: Prometheus\n  #   local-dashboard:\n  #     url: https://example.com/repository/test.json\n  #   local-dashboard-base64:\n  #     url: https://example.com/repository/test-b64.json\n  #   b64content: true\n  default:\n    prometheus-stats:\n      gnetId: 10000\n      revision: 1\n      datasource: Prometheus\n\n\n\n## Reference to external ConfigMap per provider. Use provider name as key and ConfiMap name as value.\n## A provider dashboards must be defined either by external ConfigMaps or in values.yaml, not in both.\n## ConfigMap data example:\n##\n## data:\n##   example-dashboard.json: |\n##     RAW_JSON\n##\ndashboardsConfigMaps: {}\n#  default: \"\"\n\n## Grafana's primary configuration\n## NOTE: values in map will be converted to ini format\n## ref: http://docs.grafana.org/installation/configuration/\n##\ngrafana.ini:\n  paths:\n    data: /var/lib/grafana/data\n    logs: /var/log/grafana\n    plugins: /var/lib/grafana/plugins\n    provisioning: /etc/grafana/provisioning\n  analytics:\n    check_for_updates: true\n  log:\n    mode: console\n  grafana_net:\n    url: https://grafana.net\n      ## grafana Authentication can be enabled with the following values on grafana.ini\n      # server:\n    # The full public facing url you use in browser, used for redirects and emails\n  #    root_url:\n  # https://grafana.com/docs/grafana/latest/auth/github/#enable-github-in-grafana\n  # auth.github:\n  #    enabled: false\n  #    allow_sign_up: false\n  #    scopes: user:email,read:org\n  #    auth_url: https://github.com/login/oauth/authorize\n  #    token_url: https://github.com/login/oauth/access_token\n  #    api_url: https://github.com/user\n  #    team_ids:\n  #    allowed_organizations:\n  #    client_id:\n  #    client_secret:\n  ## LDAP Authentication can be enabled with the following values on grafana.ini\n  ## NOTE: Grafana will fail to start if the value for ldap.toml is invalid\n  # auth.ldap:\n  #   enabled: true\n  #   allow_sign_up: true\n  #   config_file: /etc/grafana/ldap.toml\n\n## Grafana's LDAP configuration\n## Templated by the template in _helpers.tpl\n## NOTE: To enable the grafana.ini must be configured with auth.ldap.enabled\n## ref: http://docs.grafana.org/installation/configuration/#auth-ldap\n## ref: http://docs.grafana.org/installation/ldap/#configuration\nldap:\n  enabled: false\n  # `existingSecret` is a reference to an existing secret containing the ldap configuration\n  # for Grafana in a key `ldap-toml`.\n  existingSecret: \"\"\n  # `config` is the content of `ldap.toml` that will be stored in the created secret\n  config: \"\"\n  # config: |-\n  #   verbose_logging = true\n\n  #   [[servers]]\n  #   host = \"my-ldap-server\"\n  #   port = 636\n  #   use_ssl = true\n  #   start_tls = false\n  #   ssl_skip_verify = false\n  #   bind_dn = \"uid=%s,ou=users,dc=myorg,dc=com\"\n\n## Grafana's SMTP configuration\n## NOTE: To enable, grafana.ini must be configured with smtp.enabled\n## ref: http://docs.grafana.org/installation/configuration/#smtp\nsmtp:\n  # `existingSecret` is a reference to an existing secret containing the smtp configuration\n  # for Grafana.\n  existingSecret: \"\"\n  userKey: \"user\"\n  passwordKey: \"password\"\n\n## Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders\n## Requires at least Grafana 5 to work and can't be used together with parameters dashboardProviders, datasources and dashboards\nsidecar:\n  image:\n    repository: kiwigrid/k8s-sidecar\n    tag: 0.1.151\n    sha: \"\"\n  imagePullPolicy: IfNotPresent\n  resources: {}\n  #   limits:\n  #     cpu: 100m\n  #     memory: 100Mi\n  #   requests:\n  #     cpu: 50m\n  #     memory: 50Mi\n  # skipTlsVerify Set to true to skip tls verification for kube api calls\n  # skipTlsVerify: true\n  enableUniqueFilenames: false\n  dashboards:\n    enabled: false\n    SCProvider: true\n    # label that the configmaps with dashboards are marked with\n    label: grafana_dashboard\n    # folder in the pod that should hold the collected dashboards (unless `defaultFolderName` is set)\n    folder: /tmp/dashboards\n    # The default folder name, it will create a subfolder under the `folder` and put dashboards in there instead\n    defaultFolderName: null\n    # If specified, the sidecar will search for dashboard config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n    # provider configuration that lets grafana manage the dashboards\n    provider:\n      # name of the provider, should be unique\n      name: sidecarProvider\n      # orgid as configured in grafana\n      orgid: 1\n      # folder in which the dashboards should be imported in grafana\n      folder: ''\n      # type of the provider\n      type: file\n      # disableDelete to activate a import-only behaviour\n      disableDelete: false\n      # allow updating provisioned dashboards from the UI\n      allowUiUpdates: false\n  datasources:\n    enabled: false\n    # label that the configmaps with datasources are marked with\n    label: grafana_datasource\n    # If specified, the sidecar will search for datasource config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n  notifiers:\n    enabled: false\n    # label that the configmaps with notifiers are marked with\n    label: grafana_notifier\n    # If specified, the sidecar will search for notifier config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n\n## Override the deployment namespace\n##\nnamespaceOverride: \"\"\n",
            "vars": {
              "GRAFANA_ADMIN_PASSWORD": "5028",
              "GRAFANA_ADMIN_USER": "admin",
              "GRAFANA_SERVICE_ACCOUNT": "grafana",
              "NAMESPACE": "grafana",
              "PROMETHEUS_SVC": "prometheus-server"
            }
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "digitalocean_kubernetes_cluster",
      "name": "my_cluster",
      "provider": "provider[\"registry.terraform.io/digitalocean/digitalocean\"]",
      "instances": [
        {
          "schema_version": 3,
          "attributes": {
            "auto_upgrade": false,
            "cluster_subnet": "10.244.0.0/16",
            "created_at": "2021-10-10 05:24:19 +0000 UTC",
            "endpoint": "https://cb82b457-8658-41cc-92e7-28934b3d306c.k8s.ondigitalocean.com",
            "id": "cb82b457-8658-41cc-92e7-28934b3d306c",
            "ipv4_address": "128.199.18.84",
            "kube_config": [
              {
                "client_certificate": "",
                "client_key": "",
                "cluster_ca_certificate": "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURKekNDQWcrZ0F3SUJBZ0lDQm5Vd0RRWUpLb1pJaHZjTkFRRUxCUUF3TXpFVk1CTUdBMVVFQ2hNTVJHbG4KYVhSaGJFOWpaV0Z1TVJvd0dBWURWUVFERXhGck9ITmhZWE1nUTJ4MWMzUmxjaUJEUVRBZUZ3MHlNVEV3TVRBdwpOVEkwTWpaYUZ3MDBNVEV3TVRBd05USTBNalphTURNeEZUQVRCZ05WQkFvVERFUnBaMmwwWVd4UFkyVmhiakVhCk1CZ0dBMVVFQXhNUmF6aHpZV0Z6SUVOc2RYTjBaWElnUTBFd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUIKRHdBd2dnRUtBb0lCQVFEckNtTis5NzRmOFkzNmQwOHFuNnRBNUtxamxmWHlQMnRyMDVSR25mS014S1liV3NpMgpNUERMRndRYTRuN094dDE3Sk5OY0l2bVcyVjU3QmdaSEZ2QTBMUE1kNDVMM21sSjFKSnFySEFNcmZXRkRadm1HCnBGcHU0dXJySUN1bnhoSm55WkJuZjdqZU95dmJJU3VTMjFKaGFKUHJGdkQ1U1BaeUw2cE15SGlYblFMRUVNeTAKbnVTTXIrZ0l4S2FlUGVJQnVsYVRpRkxyY0F1ZVlGM2x1RXZNQXV4aUw4VVZSTGtZTHJQd2VXWFpObkhSL1VMUwp4YlVVY09ocDZ6bGlwaDJLbHJNQ1JEa0RNYnlxenNXamlRb3hZTUtjbjFQRjhVM2JzQkMrMTh0cC8yWWFTZ1F6CmZWVXluQUc5c3pydy9lQUxWNUtOK0pBa3VXNlFhQWdYcXFvdEFnTUJBQUdqUlRCRE1BNEdBMVVkRHdFQi93UUUKQXdJQmhqQVNCZ05WSFJNQkFmOEVDREFHQVFIL0FnRUFNQjBHQTFVZERnUVdCQlRDTWg0eGl1VVgzM2ZkTVFDcQppeVFWMDFvamJ6QU5CZ2txaGtpRzl3MEJBUXNGQUFPQ0FRRUFYcE5zSlAySXNHWno1bS90anBVMUsrSVViYzc5Cms0eWNPNC9sMzJoNzRHWlA5OGN6dFRXcCtLRlErQ0dpUDJRK050MU5CWVhPL00xYkVkUGZRYTBueGNDYk55REwKcWV3ZU43Ri9HKytKdXdncmo3S3Bia3J3M2IrQWF5UEVxNFV4WXJHSE9hNldKOGtKTDlUM2NVc3hmOEFKZWh2bQpSRzRuZEdSakRhcU8zQmErblFFMGZBYmF3ekx3NThQbWhoK2dsNTIvNHl6NEFJYTNSa2RkNG16NVpFNEpLMUk0CnNMNjBRbktXcWZ0NkpYc2JFYmZHS0hMeTlSZXVVMFNHZzZoV00zY2NjalE2Z1RQOXN5UHhOcVVOdFdOMzRvVm4KUWx1cDJib3NYbkcwMXBlWVo1ODZOWGFhSm9NK1RtMXNRWlM0K2VvTjBWTktOaytrVHQrcktnUEVsQT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K",
                "expires_at": "2021-10-17T05:31:12Z",
                "host": "https://cb82b457-8658-41cc-92e7-28934b3d306c.k8s.ondigitalocean.com",
                "raw_config": "apiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURKekNDQWcrZ0F3SUJBZ0lDQm5Vd0RRWUpLb1pJaHZjTkFRRUxCUUF3TXpFVk1CTUdBMVVFQ2hNTVJHbG4KYVhSaGJFOWpaV0Z1TVJvd0dBWURWUVFERXhGck9ITmhZWE1nUTJ4MWMzUmxjaUJEUVRBZUZ3MHlNVEV3TVRBdwpOVEkwTWpaYUZ3MDBNVEV3TVRBd05USTBNalphTURNeEZUQVRCZ05WQkFvVERFUnBaMmwwWVd4UFkyVmhiakVhCk1CZ0dBMVVFQXhNUmF6aHpZV0Z6SUVOc2RYTjBaWElnUTBFd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUIKRHdBd2dnRUtBb0lCQVFEckNtTis5NzRmOFkzNmQwOHFuNnRBNUtxamxmWHlQMnRyMDVSR25mS014S1liV3NpMgpNUERMRndRYTRuN094dDE3Sk5OY0l2bVcyVjU3QmdaSEZ2QTBMUE1kNDVMM21sSjFKSnFySEFNcmZXRkRadm1HCnBGcHU0dXJySUN1bnhoSm55WkJuZjdqZU95dmJJU3VTMjFKaGFKUHJGdkQ1U1BaeUw2cE15SGlYblFMRUVNeTAKbnVTTXIrZ0l4S2FlUGVJQnVsYVRpRkxyY0F1ZVlGM2x1RXZNQXV4aUw4VVZSTGtZTHJQd2VXWFpObkhSL1VMUwp4YlVVY09ocDZ6bGlwaDJLbHJNQ1JEa0RNYnlxenNXamlRb3hZTUtjbjFQRjhVM2JzQkMrMTh0cC8yWWFTZ1F6CmZWVXluQUc5c3pydy9lQUxWNUtOK0pBa3VXNlFhQWdYcXFvdEFnTUJBQUdqUlRCRE1BNEdBMVVkRHdFQi93UUUKQXdJQmhqQVNCZ05WSFJNQkFmOEVDREFHQVFIL0FnRUFNQjBHQTFVZERnUVdCQlRDTWg0eGl1VVgzM2ZkTVFDcQppeVFWMDFvamJ6QU5CZ2txaGtpRzl3MEJBUXNGQUFPQ0FRRUFYcE5zSlAySXNHWno1bS90anBVMUsrSVViYzc5Cms0eWNPNC9sMzJoNzRHWlA5OGN6dFRXcCtLRlErQ0dpUDJRK050MU5CWVhPL00xYkVkUGZRYTBueGNDYk55REwKcWV3ZU43Ri9HKytKdXdncmo3S3Bia3J3M2IrQWF5UEVxNFV4WXJHSE9hNldKOGtKTDlUM2NVc3hmOEFKZWh2bQpSRzRuZEdSakRhcU8zQmErblFFMGZBYmF3ekx3NThQbWhoK2dsNTIvNHl6NEFJYTNSa2RkNG16NVpFNEpLMUk0CnNMNjBRbktXcWZ0NkpYc2JFYmZHS0hMeTlSZXVVMFNHZzZoV00zY2NjalE2Z1RQOXN5UHhOcVVOdFdOMzRvVm4KUWx1cDJib3NYbkcwMXBlWVo1ODZOWGFhSm9NK1RtMXNRWlM0K2VvTjBWTktOaytrVHQrcktnUEVsQT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\n    server: https://cb82b457-8658-41cc-92e7-28934b3d306c.k8s.ondigitalocean.com\n  name: do-blr1-my-cluster\ncontexts:\n- context:\n    cluster: do-blr1-my-cluster\n    user: do-blr1-my-cluster-admin\n  name: do-blr1-my-cluster\ncurrent-context: do-blr1-my-cluster\nusers:\n- name: do-blr1-my-cluster-admin\n  user:\n    token: e9d09263bc2f9c17060c0819598c3421b94be1dd401c9f86e7935496af7c05b9\n",
                "token": "e9d09263bc2f9c17060c0819598c3421b94be1dd401c9f86e7935496af7c05b9"
              }
            ],
            "name": "my-cluster",
            "node_pool": [
              {
                "actual_node_count": 3,
                "auto_scale": false,
                "id": "12a57d25-7bc6-400c-a30d-e38f5ecd76f8",
                "labels": {},
                "max_nodes": 0,
                "min_nodes": 0,
                "name": "my-pool",
                "node_count": 3,
                "nodes": [
                  {
                    "created_at": "2021-10-10 05:24:19 +0000 UTC",
                    "droplet_id": "268603368",
                    "id": "d7aa3a68-c3fb-4ebe-8a04-1995e987ded8",
                    "name": "my-pool-uuxiq",
                    "status": "running",
                    "updated_at": "2021-10-10 05:27:38 +0000 UTC"
                  },
                  {
                    "created_at": "2021-10-10 05:24:19 +0000 UTC",
                    "droplet_id": "268603366",
                    "id": "f8ee11ef-b8d6-4e70-924e-dee482794787",
                    "name": "my-pool-uuxif",
                    "status": "running",
                    "updated_at": "2021-10-10 05:27:38 +0000 UTC"
                  },
                  {
                    "created_at": "2021-10-10 05:24:19 +0000 UTC",
                    "droplet_id": "268603367",
                    "id": "0ac933b8-43ee-4908-aea6-c2d3c1234df2",
                    "name": "my-pool-uuxiy",
                    "status": "running",
                    "updated_at": "2021-10-10 05:27:38 +0000 UTC"
                  }
                ],
                "size": "s-2vcpu-4gb",
                "tags": [],
                "taint": []
              }
            ],
            "region": "blr1",
            "service_subnet": "10.245.0.0/16",
            "status": "running",
            "surge_upgrade": true,
            "tags": [],
            "updated_at": "2021-10-10 08:26:58 +0000 UTC",
            "version": "1.21.3-do.0",
            "vpc_uuid": "d746291e-2aa3-4aa0-a15c-b747211caa7c"
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjMifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "grafana",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "grafana",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "grafana",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "8.2.0",
                "chart": "grafana",
                "name": "grafana",
                "namespace": "grafana",
                "revision": 1,
                "values": "{}",
                "version": "6.16.13"
              }
            ],
            "name": "grafana",
            "namespace": "grafana",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://grafana.github.io/helm-charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "6.16.13",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "istio_base",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "istio-1.11.3/manifests/charts/base",
            "cleanup_on_fail": true,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": true,
            "id": "istio-base",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "",
                "chart": "base",
                "name": "istio-base",
                "namespace": "istio-system",
                "revision": 1,
                "values": "null",
                "version": "1.11.3"
              }
            ],
            "name": "istio-base",
            "namespace": "istio-system",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 120,
            "values": null,
            "verify": false,
            "version": "1.11.3",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster",
            "kubernetes_namespace.istio_system"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "istio_egress",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "istio-1.11.3/manifests/charts/gateways/istio-egress",
            "cleanup_on_fail": true,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": true,
            "id": "istio-egress",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "",
                "chart": "istio-egress",
                "name": "istio-egress",
                "namespace": "istio-system",
                "revision": 1,
                "values": "null",
                "version": "1.11.3"
              }
            ],
            "name": "istio-egress",
            "namespace": "istio-system",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 120,
            "values": null,
            "verify": false,
            "version": "1.11.3",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster",
            "helm_release.istio_base",
            "helm_release.istiod",
            "kubernetes_namespace.istio_system"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "istio_ingress",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "status": "tainted",
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "istio-1.11.3/manifests/charts/gateways/istio-ingress",
            "cleanup_on_fail": true,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": true,
            "id": "istio-ingress",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "",
                "chart": "istio-ingress",
                "name": "istio-ingress",
                "namespace": "istio-system",
                "revision": 1,
                "values": "{}",
                "version": "1.11.3"
              }
            ],
            "name": "istio-ingress",
            "namespace": "istio-system",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "failed",
            "timeout": 120,
            "values": null,
            "verify": false,
            "version": "1.11.3",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster",
            "helm_release.istiod",
            "kubernetes_namespace.istio_system"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "istiod",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "istio-1.11.3/manifests/charts/istio-control/istio-discovery",
            "cleanup_on_fail": true,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": true,
            "id": "istiod",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "",
                "chart": "istio-discovery",
                "name": "istiod",
                "namespace": "istio-system",
                "revision": 1,
                "values": "null",
                "version": "1.11.3"
              }
            ],
            "name": "istiod",
            "namespace": "istio-system",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 120,
            "values": null,
            "verify": false,
            "version": "1.11.3",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster",
            "helm_release.istio_base",
            "kubernetes_namespace.istio_system"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "prometheus",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "prometheus",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "prometheus",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "2.26.0",
                "chart": "prometheus",
                "name": "prometheus",
                "namespace": "prometheus",
                "revision": 1,
                "values": "null",
                "version": "14.9.2"
              }
            ],
            "name": "prometheus",
            "namespace": "prometheus",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://prometheus-community.github.io/helm-charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "14.9.2",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "grafana",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "grafana",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "grafana",
                "resource_version": "23583",
                "uid": "c077231f-8bb9-422d-8bf8-912726ed38b0"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "istio_system",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "istio-system",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "istio-system",
                "resource_version": "1207",
                "uid": "bcb76931-fe35-4bcf-842f-f77436ddd10e"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "prometheus",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "prometheus",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "prometheus",
                "resource_version": "5498",
                "uid": "46719680-a136-4f6a-b2d3-0a553d6543a5"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ==",
          "dependencies": [
            "digitalocean_kubernetes_cluster.my_cluster"
          ]
        }
      ]
    }
  ]
}
